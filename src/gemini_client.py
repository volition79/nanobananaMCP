"""
Gemini API í´ë¼ì´ì–¸íŠ¸ (ë³´ì•ˆ ê°•í™” ë²„ì „)

Googleì˜ Gemini 2.5 Flash Image APIì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
í„°ë¯¸ë„ í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ , ì˜¤ì§ .env íŒŒì¼ ë˜ëŠ” MCP ì„¤ì •ì—ì„œë§Œ API í‚¤ë¥¼ ì½ìŠµë‹ˆë‹¤.
"""

import asyncio
import logging
import time
from typing import List, Optional, Dict, Any, Union, Tuple
from pathlib import Path
from io import BytesIO

from google import genai
from google.genai.types import GenerateContentConfig, Modality
from PIL import Image
import httpx

from .config import get_settings
from .config_keyloader import SecureKeyLoader
from .constants import (
    GEMINI_MODEL_NAME, 
    GEMINI_TOKENS_PER_IMAGE,
    GEMINI_COST_PER_IMAGE,
    ERROR_CODES,
    MAX_RETRIES,
    RETRY_BACKOFF_FACTOR
)

logger = logging.getLogger(__name__)


class GeminiAPIError(Exception):
    """Gemini API ê´€ë ¨ ì˜ˆì™¸"""
    
    def __init__(self, message: str, code: str = None, details: dict = None):
        self.message = message
        self.code = code
        self.details = details or {}
        super().__init__(message)


class GeminiRateLimitError(GeminiAPIError):
    """API ìš”ì²­ ì œí•œ ì˜ˆì™¸"""
    pass


class GeminiQuotaExceededError(GeminiAPIError):
    """API í• ë‹¹ëŸ‰ ì´ˆê³¼ ì˜ˆì™¸"""
    pass


class GeminiClientFactory:
    """
    ë³´ì•ˆ ê°•í™”ëœ Gemini í´ë¼ì´ì–¸íŠ¸ íŒ©í† ë¦¬
    
    í„°ë¯¸ë„ í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ëª…ì‹œì ìœ¼ë¡œ API í‚¤ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
    ìš°ì„ ìˆœìœ„: MCP ì„¤ì • > .env íŒŒì¼ > ì˜¤ë¥˜ ë°œìƒ
    """
    
    def __init__(
        self,
        mcp_settings_path: Optional[str] = None,
        mcp_server_name: str = "nanobanana",
        env_file: str = ".env",
        use_vertex_ai: bool = False,
        project: str = "",
        location: str = "us-central1"
    ):
        """
        íŒ©í† ë¦¬ ì´ˆê¸°í™”
        
        Args:
            mcp_settings_path: MCP ì„¤ì • íŒŒì¼ ê²½ë¡œ
            mcp_server_name: MCP ì„œë²„ ì´ë¦„
            env_file: .env íŒŒì¼ ê²½ë¡œ
            use_vertex_ai: Vertex AI ì‚¬ìš© ì—¬ë¶€
            project: Google Cloud í”„ë¡œì íŠ¸ ID (Vertex AI ìš©)
            location: Google Cloud ìœ„ì¹˜ (Vertex AI ìš©)
        """
        self.use_vertex_ai = use_vertex_ai
        self.project = project
        self.location = location
        
        # ë³´ì•ˆ í‚¤ ë¡œë”ë¡œ API í‚¤ íšë“
        self.key_loader = SecureKeyLoader(
            mcp_settings_path=mcp_settings_path,
            mcp_server_name=mcp_server_name,
            env_file=env_file
        )
        
        self.api_key = self.key_loader.get_api_key()
        
        # API í‚¤ ê²€ì¦
        if not self.api_key and not use_vertex_ai:
            raise RuntimeError(
                "Gemini API key not found. Please set it in:\n"
                "1. MCP server configuration (recommended): mcpServers.{server_name}.env.GEMINI_API_KEY\n"
                "2. .env file: GEMINI_API_KEY, GOOGLE_API_KEY, or GOOGLE_AI_API_KEY\n"
                "\nSupported key names: GEMINI_API_KEY, GOOGLE_API_KEY, GOOGLE_AI_API_KEY"
            )
        
        # Vertex AI ê²€ì¦
        if use_vertex_ai and not (project and location):
            raise RuntimeError("Vertex AI mode requires both project and location parameters.")
        
        # í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        self.client = self._create_client()
        
        # ë””ë²„ê·¸ ì •ë³´ ë¡œê·¸
        debug_info = self.key_loader.get_debug_info()
        pollution_check = self.key_loader.verify_no_os_env_pollution()
        
        logger.info(f"ğŸ” API Key Source: {debug_info['key_info']['source_name']}")
        logger.info(f"ğŸ” Key Name: {debug_info['key_info']['key_name']}")
        logger.info(f"ğŸ” {pollution_check['message']}")
        
        if logger.isEnabledFor(logging.DEBUG):
            logger.debug(f"Full debug info: {debug_info}")
            logger.debug(f"Pollution check: {pollution_check}")
    
    def _create_client(self) -> genai.Client:
        """
        Gemini í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ëª…ì‹œì  API í‚¤ ì „ë‹¬)
        
        Returns:
            genai.Client: ì„¤ì •ëœ í´ë¼ì´ì–¸íŠ¸
        """
        try:
            if self.use_vertex_ai:
                # Vertex AI ëª¨ë“œ: í”„ë¡œì íŠ¸ì™€ ìœ„ì¹˜ ëª…ì‹œ
                client = genai.Client(
                    vertexai=True,
                    project=self.project,
                    location=self.location,
                    api_key=self.api_key  # Noneì´ì–´ë„ Vertex AIê°€ ADC ì‚¬ìš©
                )
                logger.info(f"âœ… Vertex AI client created - Project: {self.project}, Location: {self.location}")
            else:
                # ì¼ë°˜ ëª¨ë“œ: API í‚¤ ëª…ì‹œì  ì „ë‹¬
                client = genai.Client(api_key=self.api_key)
                logger.info("âœ… Gemini API client created with explicit key")
            
            return client
            
        except Exception as e:
            logger.error(f"âŒ Failed to create Gemini client: {e}")
            raise GeminiAPIError(f"Client creation failed: {str(e)}")
    
    def get_client(self) -> genai.Client:
        """í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
        return self.client
    
    def get_debug_source(self) -> str:
        """API í‚¤ ì¶œì²˜ ë°˜í™˜ (ë””ë²„ê¹…ìš©)"""
        return self.key_loader.key_info.get('source_name', 'unknown')
    
    def get_full_debug_info(self) -> Dict[str, Any]:
        """ì „ì²´ ë””ë²„ê·¸ ì •ë³´ ë°˜í™˜"""
        return {
            "client_info": {
                "use_vertex_ai": self.use_vertex_ai,
                "project": self.project,
                "location": self.location
            },
            "key_loader": self.key_loader.get_debug_info(),
            "pollution_check": self.key_loader.verify_no_os_env_pollution()
        }


class GeminiClient:
    """
    Gemini 2.5 Flash Image API í´ë¼ì´ì–¸íŠ¸ (ë³´ì•ˆ ê°•í™” ë²„ì „)
    """
    
    def __init__(self, settings=None, client_factory: Optional[GeminiClientFactory] = None):
        """
        í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        
        Args:
            settings: ì„¤ì • ê°ì²´ (ì„ íƒì‚¬í•­)
            client_factory: í´ë¼ì´ì–¸íŠ¸ íŒ©í† ë¦¬ (ì„ íƒì‚¬í•­)
        """
        self.settings = settings or get_settings()
        
        # í´ë¼ì´ì–¸íŠ¸ íŒ©í† ë¦¬ ì„¤ì •
        if client_factory:
            self.factory = client_factory
        else:
            self.factory = GeminiClientFactory(
                mcp_server_name="nanobanana",
                use_vertex_ai=self.settings.google_genai_use_vertexai,
                project=self.settings.google_cloud_project,
                location=self.settings.google_cloud_location
            )
        
        self._client = self.factory.get_client()
        
        # ìš”ì²­ í†µê³„
        self._request_count = 0
        self._total_images_generated = 0
        self._total_cost = 0.0
        self._start_time = time.time()
        
        logger.info("ğŸš€ Gemini client initialized with secure key loading")
    
    async def health_check(self) -> Dict[str, Any]:
        """
        API ì—°ê²° ìƒíƒœ ë° ëª¨ë¸ ì ‘ê·¼ì„± í™•ì¸
        
        Returns:
            Dict[str, Any]: ìƒíƒœ ì •ë³´
        """
        try:
            # ëª¨ë¸ ëª©ë¡ ì¡°íšŒë¡œ ì—°ê²° í…ŒìŠ¤íŠ¸
            models = list(self._client.models.list())
            
            # ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ ì°¾ê¸°
            image_models = [
                model for model in models 
                if 'image' in model.name.lower() or 'flash' in model.name.lower()
            ]
            
            return {
                "status": "healthy",
                "api_accessible": True,
                "total_models": len(models),
                "image_models": len(image_models),
                "target_model": GEMINI_MODEL_NAME,
                "model_available": any(GEMINI_MODEL_NAME in model.name for model in models),
                "key_source": self.factory.get_debug_source(),
                "timestamp": time.time()
            }
            
        except Exception as e:
            logger.error(f"Health check failed: {e}")
            return {
                "status": "unhealthy",
                "api_accessible": False,
                "error": str(e),
                "key_source": self.factory.get_debug_source(),
                "timestamp": time.time()
            }
    
    async def generate_image(
        self,
        prompt: str,
        aspect_ratio: Optional[str] = None,
        style: Optional[str] = None,
        quality: Optional[str] = "high",
        candidate_count: int = 1
    ) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° ì´ë¯¸ì§€ ìƒì„±
        
        Args:
            prompt: ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸
            aspect_ratio: ì´ë¯¸ì§€ ë¹„ìœ¨
            style: ìŠ¤íƒ€ì¼
            quality: í’ˆì§ˆ
            candidate_count: ìƒì„±í•  ì´ë¯¸ì§€ ìˆ˜
            
        Returns:
            Dict[str, Any]: ìƒì„± ê²°ê³¼
        """
        try:
            # ìš”ì²­ í†µê³„ ì—…ë°ì´íŠ¸
            self._request_count += 1
            
            # ìƒì„± ì„¤ì •
            config = GenerateContentConfig(
                candidate_count=min(candidate_count, 4),
                temperature=0.7
            )
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            full_prompt = self._build_image_prompt(prompt, aspect_ratio, style)
            
            # ì´ë¯¸ì§€ ìƒì„± ìš”ì²­
            response = await asyncio.to_thread(
                self._client.models.generate_content,
                model=GEMINI_MODEL_NAME,
                contents=[full_prompt],
                config=config
            )
            
            # ì‘ë‹µ ì²˜ë¦¬
            if not response or not response.candidates:
                raise GeminiAPIError("No candidates returned from API")
            
            images = []
            for candidate in response.candidates:
                if candidate.content and candidate.content.parts:
                    for part in candidate.content.parts:
                        if hasattr(part, 'inline_data') and part.inline_data:
                            images.append({
                                "data": part.inline_data.data,
                                "mime_type": part.inline_data.mime_type
                            })
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._total_images_generated += len(images)
            self._total_cost += len(images) * GEMINI_COST_PER_IMAGE
            
            return {
                "success": True,
                "images": images,
                "count": len(images),
                "prompt_used": full_prompt,
                "tokens_consumed": len(images) * GEMINI_TOKENS_PER_IMAGE,
                "cost_estimate": len(images) * GEMINI_COST_PER_IMAGE
            }
            
        except Exception as e:
            logger.error(f"Image generation failed: {e}")
            return {
                "success": False,
                "error": str(e),
                "images": [],
                "count": 0
            }
    
    async def edit_image(
        self,
        image_path: str,
        edit_prompt: str,
        mask_path: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ ìì—°ì–´ ëª…ë ¹ìœ¼ë¡œ í¸ì§‘
        
        Args:
            image_path: í¸ì§‘í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            edit_prompt: í¸ì§‘ ì§€ì‹œì‚¬í•­
            mask_path: ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            **kwargs: ì¶”ê°€ ì„¤ì •
            
        Returns:
            Dict[str, Any]: í¸ì§‘ ê²°ê³¼
        """
        try:
            # ìš”ì²­ í†µê³„ ì—…ë°ì´íŠ¸
            self._request_count += 1
            
            # ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì–´ì„œ ì¸ë¼ì¸ ë°ì´í„°ë¡œ ë³€í™˜
            image_path = Path(image_path)
            if not image_path.exists():
                raise GeminiAPIError(f"Image file not found: {image_path}")
            
            # PIL Imageë¡œ ì½ê¸°
            pil_image = Image.open(image_path)
            
            # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜ (PNG í˜•ì‹ìœ¼ë¡œ ì €ì¥)
            image_bytes = BytesIO()
            pil_image.save(image_bytes, format='PNG')
            image_bytes.seek(0)
            image_data = image_bytes.getvalue()
            
            # í¸ì§‘ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            full_prompt = f"Edit this image: {edit_prompt}"
            
            # ìƒì„± ì„¤ì •
            config = GenerateContentConfig(
                candidate_count=1,
                temperature=0.7
            )
            
            # ì´ë¯¸ì§€ í¸ì§‘ ìš”ì²­ (ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•˜ì—¬ ìƒˆë¡œìš´ ì´ë¯¸ì§€ ìƒì„±)
            response = await asyncio.to_thread(
                self._client.models.generate_content,
                model=GEMINI_MODEL_NAME,
                contents=[
                    {
                        "role": "user",
                        "parts": [
                            {"text": full_prompt},
                            {"inline_data": {"mime_type": "image/png", "data": image_data}}
                        ]
                    }
                ],
                config=config
            )
            
            # ì‘ë‹µ ì²˜ë¦¬
            if not response or not response.candidates:
                raise GeminiAPIError("No candidates returned from API")
            
            images = []
            for candidate in response.candidates:
                if candidate.content and candidate.content.parts:
                    for part in candidate.content.parts:
                        if hasattr(part, 'inline_data') and part.inline_data:
                            images.append({
                                "data": part.inline_data.data,
                                "mime_type": part.inline_data.mime_type
                            })
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._total_images_generated += len(images)
            self._total_cost += len(images) * GEMINI_COST_PER_IMAGE
            
            return {
                "success": True,
                "images": images,
                "count": len(images),
                "prompt_used": full_prompt,
                "tokens_consumed": len(images) * GEMINI_TOKENS_PER_IMAGE,
                "cost_estimate": len(images) * GEMINI_COST_PER_IMAGE
            }
            
        except Exception as e:
            logger.error(f"Image editing failed: {e}")
            return {
                "success": False,
                "error": str(e),
                "images": [],
                "count": 0
            }

    async def blend_images(
        self,
        image_paths: List[str],
        blend_prompt: str,
        **kwargs
    ) -> Dict[str, Any]:
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ë¸”ë Œë”©í•˜ì—¬ ìƒˆë¡œìš´ ì´ë¯¸ì§€ ìƒì„±
        
        Args:
            image_paths: ë¸”ë Œë”©í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë“¤
            blend_prompt: ë¸”ë Œë”© ì§€ì‹œì‚¬í•­
            **kwargs: ì¶”ê°€ ì„¤ì •
            
        Returns:
            Dict[str, Any]: ë¸”ë Œë”© ê²°ê³¼
        """
        try:
            # ìš”ì²­ í†µê³„ ì—…ë°ì´íŠ¸
            self._request_count += 1
            
            # ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ì½ì–´ì„œ ì¸ë¼ì¸ ë°ì´í„°ë¡œ ë³€í™˜
            image_parts = []
            for i, image_path in enumerate(image_paths):
                image_path = Path(image_path)
                if not image_path.exists():
                    raise GeminiAPIError(f"Image file not found: {image_path}")
                
                # PIL Imageë¡œ ì½ê¸°
                pil_image = Image.open(image_path)
                
                # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜ (PNG í˜•ì‹ìœ¼ë¡œ ì €ì¥)
                image_bytes = BytesIO()
                pil_image.save(image_bytes, format='PNG')
                image_bytes.seek(0)
                image_data = image_bytes.getvalue()
                
                # ì´ë¯¸ì§€ íŒŒíŠ¸ ì¶”ê°€
                image_parts.append({
                    "inline_data": {
                        "mime_type": "image/png", 
                        "data": image_data
                    }
                })
            
            # ë¸”ë Œë”© í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            full_prompt = f"Blend these {len(image_paths)} images: {blend_prompt}"
            
            # ìƒì„± ì„¤ì •
            config = GenerateContentConfig(
                candidate_count=1,
                temperature=0.7
            )
            
            # ì´ë¯¸ì§€ ë¸”ë Œë”© ìš”ì²­ (ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•˜ì—¬ ìƒˆë¡œìš´ ì´ë¯¸ì§€ ìƒì„±)
            content_parts = [{"text": full_prompt}] + image_parts
            
            response = await asyncio.to_thread(
                self._client.models.generate_content,
                model=GEMINI_MODEL_NAME,
                contents=[
                    {
                        "role": "user",
                        "parts": content_parts
                    }
                ],
                config=config
            )
            
            # ì‘ë‹µ ì²˜ë¦¬
            if not response or not response.candidates:
                raise GeminiAPIError("No candidates returned from API")
            
            images = []
            for candidate in response.candidates:
                if candidate.content and candidate.content.parts:
                    for part in candidate.content.parts:
                        if hasattr(part, 'inline_data') and part.inline_data:
                            images.append({
                                "data": part.inline_data.data,
                                "mime_type": part.inline_data.mime_type
                            })
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._total_images_generated += len(images)
            self._total_cost += len(images) * GEMINI_COST_PER_IMAGE
            
            return {
                "success": True,
                "images": images,
                "count": len(images),
                "prompt_used": full_prompt,
                "tokens_consumed": len(images) * GEMINI_TOKENS_PER_IMAGE,
                "cost_estimate": len(images) * GEMINI_COST_PER_IMAGE
            }
            
        except Exception as e:
            logger.error(f"Image blending failed: {e}")
            return {
                "success": False,
                "error": str(e),
                "images": [],
                "count": 0
            }

    def _build_image_prompt(
        self, 
        prompt: str, 
        aspect_ratio: Optional[str] = None,
        style: Optional[str] = None
    ) -> str:
        """ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        parts = [prompt]
        
        if aspect_ratio:
            parts.append(f"Aspect ratio: {aspect_ratio}")
        
        if style:
            parts.append(f"Style: {style}")
        
        return ". ".join(parts)
    
    def get_statistics(self) -> Dict[str, Any]:
        """ì‚¬ìš© í†µê³„ ë°˜í™˜"""
        uptime = time.time() - self._start_time
        
        return {
            "requests_made": self._request_count,
            "images_generated": self._total_images_generated,
            "estimated_cost": round(self._total_cost, 4),
            "uptime_seconds": round(uptime, 2),
            "avg_images_per_request": (
                round(self._total_images_generated / self._request_count, 2)
                if self._request_count > 0 else 0
            ),
            "key_source": self.factory.get_debug_source()
        }
    
    def reset_statistics(self) -> None:
        """í†µê³„ ì´ˆê¸°í™”"""
        self._request_count = 0
        self._total_images_generated = 0
        self._total_cost = 0.0
        self._start_time = time.time()
        logger.info("Statistics reset")
    
    def get_debug_info(self) -> Dict[str, Any]:
        """ë””ë²„ê·¸ ì •ë³´ ë°˜í™˜"""
        return {
            "statistics": self.get_statistics(),
            "factory_debug": self.factory.get_full_debug_info(),
            "client_status": "initialized" if self._client else "not_initialized"
        }


# ì „ì—­ í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
_global_client: Optional[GeminiClient] = None


async def create_gemini_client(settings=None) -> GeminiClient:
    """
    Gemini í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ë¹„ë™ê¸°)
    
    Args:
        settings: ì„¤ì • ê°ì²´
        
    Returns:
        GeminiClient: ì´ˆê¸°í™”ëœ í´ë¼ì´ì–¸íŠ¸
    """
    global _global_client
    
    if _global_client is None:
        logger.info("Creating new Gemini client...")
        _global_client = GeminiClient(settings=settings)
        
        # í—¬ìŠ¤ì²´í¬ ì‹¤í–‰
        health = await _global_client.health_check()
        if not health["api_accessible"]:
            logger.warning(f"API accessibility check failed: {health.get('error', 'Unknown error')}")
        else:
            logger.info("âœ… Gemini API health check passed")
    
    return _global_client


def get_gemini_client() -> Optional[GeminiClient]:
    """ì „ì—­ í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return _global_client


def reset_gemini_client():
    """ì „ì—­ í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”"""
    global _global_client
    _global_client = None
    logger.info("Global Gemini client reset")